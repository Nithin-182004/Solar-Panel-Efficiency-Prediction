{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "f92b7555-3886-4a8d-8b2f-1947e748b55d",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error\nimport xgboost as xgb\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Load datasets\ntrain_df = pd.read_csv('train.csv')\ntest_df = pd.read_csv('test.csv')\nsample_submission = pd.read_csv('sample_submission.csv')\n\n# Define features and target\nfeatures = [col for col in train_df.columns if col not in ['id', 'efficiency']]\ntarget = 'efficiency'\n\n# Data cleaning\ndef clean_data(df):\n    df = df.copy()\n    # Define numerical columns explicitly\n    numerical_cols = ['temperature', 'irradiance', 'humidity', 'panel_age', 'maintenance_count',\n                     'soiling_ratio', 'voltage', 'current', 'module_temperature', 'cloud_coverage',\n                     'wind_speed', 'pressure']\n    \n    # Convert all numerical columns to numeric, handling non-numeric values\n    for col in numerical_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    # Cap cloud_coverage at 100\n    df['cloud_coverage'] = df['cloud_coverage'].clip(upper=100)\n    \n    # Ensure soiling_ratio is between 0 and 1\n    df['soiling_ratio'] = df['soiling_ratio'].clip(0, 1)\n    \n    # Handle missing categorical values\n    for col in ['error_code', 'installation_type']:\n        df[col] = df[col].replace('', 'Unknown').fillna('Unknown')\n    \n    # Debugging: Check for non-numeric values in numerical columns\n    for col in numerical_cols:\n        non_numeric = df[col][df[col].apply(lambda x: isinstance(x, str))].unique()\n        if len(non_numeric) > 0:\n            print(f\"Non-numeric values in {col}: {non_numeric}\")\n    \n    return df\n\n# Feature engineering\ndef engineer_features(df):\n    df = df.copy()\n    # Power output\n    df['power_output'] = df['voltage'] * df['current']\n    # Temperature difference\n    df['temp_diff'] = df['module_temperature'] - df['temperature']\n    # Degradation rate\n    df['degradation_rate'] = df['panel_age'] / (df['maintenance_count'] + 1)\n    # Error indicator\n    df['has_error'] = df['error_code'].apply(lambda x: 0 if x == 'E00' else 1)\n    # Soiling impact\n    df['soiling_impact'] = 1 - df['soiling_ratio']\n    # Effective irradiance\n    df['effective_irradiance'] = df['irradiance'] * (1 - df['cloud_coverage'] / 100)\n    \n    # Handle NaN in engineered features\n    engineered_cols = ['power_output', 'temp_diff', 'degradation_rate', 'soiling_impact', 'effective_irradiance']\n    for col in engineered_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    return df\n\n# Apply cleaning and feature engineering\ntrain_df = clean_data(train_df)\ntest_df = clean_data(test_df)\ntrain_df = engineer_features(train_df)\ntest_df = engineer_features(test_df)\n\n# Define numerical and categorical columns\nnumerical_cols = ['temperature', 'irradiance', 'humidity', 'panel_age', 'maintenance_count',\n                 'soiling_ratio', 'voltage', 'current', 'module_temperature', 'cloud_coverage',\n                 'wind_speed', 'pressure', 'power_output', 'temp_diff', 'degradation_rate',\n                 'soiling_impact', 'effective_irradiance']\ncategorical_cols = ['string_id', 'error_code', 'installation_type']\n\n# Debugging: Verify numerical columns are numeric\nfor col in numerical_cols:\n    if train_df[col].dtype not in ['int64', 'float64']:\n        print(f\"Column {col} is not numeric: {train_df[col].dtype}\")\n        print(f\"Unique values in {col}: {train_df[col].unique()[:10]}\")\n\n# Preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', Pipeline([\n            ('imputer', SimpleImputer(strategy='median')),\n            ('scaler', StandardScaler())\n        ]), numerical_cols),\n        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_cols)\n    ])\n\n# Define the model pipeline\nmodel = Pipeline([\n    ('preprocessor', preprocessor),\n    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=42))\n])\n\n# Split training data\nX = train_df[numerical_cols + categorical_cols]\ny = train_df[target]\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Evaluate on validation set\ny_pred = model.predict(X_val)\nrmse = np.sqrt(mean_squared_error(y_val, y_pred))\nscore = 100 * (1 - rmse)\nprint(f'Validation Score: {score:.4f}')\n\n# Hyperparameter tuning\nparam_grid = {\n    'regressor__n_estimators': [100, 200, 300],\n    'regressor__max_depth': [3, 5, 7],\n    'regressor__learning_rate': [0.01, 0.05, 0.1]\n}\ngrid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid_search.fit(X_train, y_train)\n\n# Best model\nbest_model = grid_search.best_estimator_\ny_pred_best = best_model.predict(X_val)\nrmse_best = np.sqrt(mean_squared_error(y_val, y_pred_best))\nscore_best = 100 * (1 - rmse_best)\nprint(f'Best Validation Score: {score_best:.4f}')\nprint(f'Best Parameters: {grid_search.best_params_}')\n\n# Generate predictions on test set\ntest_features = test_df[numerical_cols + categorical_cols]\ntest_predictions = best_model.predict(test_features)\n\n# Prepare submission file\nsubmission = pd.DataFrame({\n    'id': test_df['id'],\n    'efficiency': test_predictions\n})\n\n# Ensure submission matches required format\nassert submission.shape == (12000, 2), f\"Submission shape {submission.shape} does not match required (12000, 2)\"\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved as 'submission.csv'\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Validation Score: 88.7587\n"
        }
      ],
      "execution_count": null
    },
    {
      "id": "0c11374c-581c-4b2d-a202-322b50316ee1",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}